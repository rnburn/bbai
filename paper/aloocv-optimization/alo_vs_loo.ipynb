{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare ALO Optimization to Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook compares ALO to grid search on a variety of real-world data sets.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import peak_engines\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions for Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_indicator(df, name, drop_original=True):\n",
    "    value = df[name]\n",
    "    unique_value = set(value)\n",
    "    for i, val in enumerate(unique_value):\n",
    "        df[name + \"_\" + str(i)] = (value == val) + 0.0\n",
    "    if drop_original:\n",
    "        df.drop(labels=name, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute LO Via Brute Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lo(X, y, C):\n",
    "    model = LogisticRegression(C=C)\n",
    "    result = 0\n",
    "    values = sorted(list(set(y)))\n",
    "    for train_indexes, test_indexes in LeaveOneOut().split(X):\n",
    "        X_train = X[train_indexes]\n",
    "        X_test = X[test_indexes]\n",
    "        y_train = y[train_indexes]\n",
    "        y_test = y[test_indexes]\n",
    "        model.fit(X_train, y_train)\n",
    "        pred = model.predict_proba(X_test)[0]\n",
    "        index = values.index(y_test[0])\n",
    "        result += np.log(pred[index])\n",
    "    return result / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models(X, y):\n",
    "    # grid search with default parameters\n",
    "    model_grid = LogisticRegressionCV(random_state=0, scoring='neg_log_loss')\n",
    "    model_grid.fit(X, y)\n",
    "    C_grid = model_grid.C_[0]\n",
    "    lambda_grid = 1 / (2*C_grid)\n",
    "    print(\"grid\", lambda_grid, compute_lo(X, y, C_grid))\n",
    "    \n",
    "    # ALO optimization\n",
    "    model_alo = peak_engines.LogisticRegressionModel()\n",
    "    model_alo.fit(X, y)\n",
    "    C_alo = model_alo.C_[0]\n",
    "    lambda_alo = 1 / (2*C_alo)\n",
    "    print(\"alo\", lambda_alo, compute_lo(X, y, C_alo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid 1.391279701103563 -0.07704148045383749\n",
      "alo 0.7512990318459845 -0.07490235610619664\n"
     ]
    }
   ],
   "source": [
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "fit_models(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleveland Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "df = pd.read_csv(url, header=None, na_values=\"?\")\n",
    "df = df.dropna()\n",
    "df.columns = [\n",
    "        'age',\n",
    "        'sex',\n",
    "        'cp',\n",
    "        'trestbps',\n",
    "        'chol',\n",
    "        'fbs',\n",
    "        'restecg',\n",
    "        'thalach',\n",
    "        'exang',\n",
    "        'oldpeak',\n",
    "        'slope',\n",
    "        'ca',\n",
    "        'thal',\n",
    "        'num',\n",
    "]\n",
    "to_indicator(df, 'cp')\n",
    "to_indicator(df, 'restecg')\n",
    "to_indicator(df, 'slope')\n",
    "to_indicator(df, 'thal')\n",
    "y = np.array(df['num'])\n",
    "df = df.drop(columns=[\"num\"])\n",
    "X = np.array(df.iloc[:,:].values, dtype=float)\n",
    "y = y > 0\n",
    "y = 2*y - 1\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid 1.391279701103563 -0.3846047408578833\n",
      "alo 4.785417311146802 -0.37907062783574563\n"
     ]
    }
   ],
   "source": [
    "fit_models(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arcene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_X_train = 'https://archive.ics.uci.edu/ml/machine-learning-databases/arcene/ARCENE/arcene_train.data'\n",
    "url_y_train = 'https://archive.ics.uci.edu/ml/machine-learning-databases/arcene/ARCENE/arcene_train.labels'\n",
    "url_X_valid = 'https://archive.ics.uci.edu/ml/machine-learning-databases/arcene/ARCENE/arcene_valid.data'\n",
    "url_y_valid = 'https://archive.ics.uci.edu/ml/machine-learning-databases/arcene/arcene_valid.labels'\n",
    "X_train = pd.read_csv(url_X_train, delim_whitespace=True, header=None).iloc[:,:].values\n",
    "y_train = pd.read_csv(url_y_train, delim_whitespace=True, header=None).iloc[:,0].values\n",
    "X_valid = pd.read_csv(url_X_valid, delim_whitespace=True, header=None).iloc[:,:].values\n",
    "y_valid = pd.read_csv(url_y_valid, delim_whitespace=True, header=None).iloc[:,0].values\n",
    "X = np.vstack((X_train, X_valid))\n",
    "y = np.concatenate((y_train, y_valid))\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid 10.772173450159421 -0.3035087160885871\n",
      "alo 7.229829676854908 -0.30324111580909746\n"
     ]
    }
   ],
   "source": [
    "fit_models(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
